{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Trojan Detection ML Model\n",
    "\n",
    "This notebook implements a comprehensive machine learning model for detecting Android banking trojans using both static and dynamic analysis features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.append('..')\n",
    "from static_feature_extractor import extract_static_features, extract_features_batch\n",
    "from dynamic_feature_extractor import extract_dynamic_features, create_mock_dynamic_features\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('../data')\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "MODELS_DIR = Path('../models')\n",
    "\n",
    "# Create directories\n",
    "for directory in [PROCESSED_DIR, MODELS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Models: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset for demonstration\n",
    "def create_synthetic_features(n_malware=200, n_benign=200):\n",
    "    np.random.seed(42)\n",
    "    features = []\n",
    "    \n",
    "    # Generate malware features\n",
    "    for i in range(n_malware):\n",
    "        feature = {\n",
    "            'sha256': f'malware_{i:04d}',\n",
    "            'total_permissions': np.random.randint(15, 40),\n",
    "            'sensitive_api_count': np.random.randint(10, 50),\n",
    "            'obfuscation_score': np.random.randint(20, 200),\n",
    "            'exported_components': np.random.randint(2, 15),\n",
    "            'has_native_code': np.random.choice([0, 1], p=[0.4, 0.6]),\n",
    "            'pkg_has_bank_keyword': np.random.choice([0, 1], p=[0.3, 0.7]),\n",
    "            'sensitive_api_runtime': np.random.randint(10, 60),\n",
    "            'suspicious_syscalls': np.random.randint(5, 40),\n",
    "            'suspicious_domain_hits': np.random.randint(1, 8),\n",
    "            'malicious_behavior_score': np.random.uniform(10, 50),\n",
    "            'label': 1\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    # Generate benign features\n",
    "    for i in range(n_benign):\n",
    "        feature = {\n",
    "            'sha256': f'benign_{i:04d}',\n",
    "            'total_permissions': np.random.randint(8, 25),\n",
    "            'sensitive_api_count': np.random.randint(0, 15),\n",
    "            'obfuscation_score': np.random.randint(0, 50),\n",
    "            'exported_components': np.random.randint(0, 8),\n",
    "            'has_native_code': np.random.choice([0, 1], p=[0.6, 0.4]),\n",
    "            'pkg_has_bank_keyword': np.random.choice([0, 1], p=[0.2, 0.8]),\n",
    "            'sensitive_api_runtime': np.random.randint(0, 20),\n",
    "            'suspicious_syscalls': np.random.randint(0, 15),\n",
    "            'suspicious_domain_hits': np.random.randint(0, 3),\n",
    "            'malicious_behavior_score': np.random.uniform(0, 15),\n",
    "            'label': 0\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "# Create dataset\n",
    "df = create_synthetic_features()\n",
    "print(f\"Created dataset with {len(df)} samples\")\n",
    "print(f\"Class distribution: {df['label'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for training\n",
    "feature_columns = [col for col in df.columns if col not in ['sha256', 'label']]\n",
    "X = df[feature_columns]\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=2.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nMODEL EVALUATION RESULTS\")\n",
    "print(\"=\"*40)\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "for _, row in feature_importance.head(10).iterrows():\n",
    "    print(f\"{row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = MODELS_DIR / 'banking_trojan_detector.joblib'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_names_path = MODELS_DIR / 'feature_names.csv'\n",
    "pd.Series(X.columns).to_csv(feature_names_path, index=False, header=['feature'])\n",
    "print(f\"Feature names saved to: {feature_names_path}\")\n",
    "\n",
    "# Save feature importance\n",
    "importance_path = MODELS_DIR / 'feature_importance.csv'\n",
    "feature_importance.to_csv(importance_path, index=False)\n",
    "print(f\"Feature importance saved to: {importance_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Predict on new sample\n",
    "def predict_sample(sample_features):\n",
    "    \"\"\"Predict if a sample is malware or benign.\"\"\"\n",
    "    sample_df = pd.DataFrame([sample_features])\n",
    "    prediction = model.predict(sample_df)[0]\n",
    "    probability = model.predict_proba(sample_df)[0, 1]\n",
    "    \n",
    "    label = \"MALWARE\" if prediction == 1 else \"BENIGN\"\n",
    "    return label, probability\n",
    "\n",
    "# Test with a suspicious sample\n",
    "suspicious_sample = {\n",
    "    'total_permissions': 35,\n",
    "    'sensitive_api_count': 45,\n",
    "    'obfuscation_score': 150,\n",
    "    'exported_components': 12,\n",
    "    'has_native_code': 1,\n",
    "    'pkg_has_bank_keyword': 1,\n",
    "    'sensitive_api_runtime': 50,\n",
    "    'suspicious_syscalls': 30,\n",
    "    'suspicious_domain_hits': 5,\n",
    "    'malicious_behavior_score': 40.0\n",
    "}\n",
    "\n",
    "label, prob = predict_sample(suspicious_sample)\n",
    "print(f\"Prediction: {label} (confidence: {prob:.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
